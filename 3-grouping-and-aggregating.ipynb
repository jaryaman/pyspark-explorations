{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edee53d7-9b7d-4e35-a490-a5d34737138b",
   "metadata": {},
   "source": [
    "# Grouping and aggregating spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ad7a87-21fd-4eb9-adeb-d24654eb3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pathlib import Path\n",
    "data_dir = Path('../pyspark/Python-and-Spark-for-Big-Data-master/Spark_DataFrames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403477b7-c1ac-4c8f-9909-65f492e58ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/09 14:42:21 WARN Utils: Your hostname, GBLON1WLZ13699 resolves to a loopback address: 127.0.1.1; using 10.69.14.157 instead (on interface eth2)\n",
      "21/07/09 14:42:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/juvid/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/07/09 14:42:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('aggs').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f59d3d-6420-4bf7-87bb-d31f28ddaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = str(data_dir/'sales_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1feaf736-e0a6-4f15-bdf8-caf05a074d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(data_path, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd6cfed-7451-45bb-8327-f2b869de4c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65966ad-c06a-4b89-8705-dc65d45f65d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c678a496-e88a-4f48-9410-2e203656f8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   APPL|            370.0|\n",
      "|   GOOG|            220.0|\n",
      "|     FB|            610.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Company').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46109893-5775-4c52-a690-04b14f01fe14",
   "metadata": {},
   "source": [
    "Aggregate without grouping. Takes a dict of columns and operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b57acd6c-e17a-4735-948d-771b260fe129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(Sales)|\n",
      "+----------+\n",
      "|     870.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Sales':'max'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7257aa40-1164-4d54-ab8a-d7e413d7d5c8",
   "metadata": {},
   "source": [
    "We can also use this dict syntax for grouping too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59b3ca96-fb57-4684-a627-1dd3d7b4ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = df.groupBy('Company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "776d38ec-90c4-4181-aeaf-bd68bb5bdd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|     750.0|\n",
      "|   GOOG|     340.0|\n",
      "|     FB|     870.0|\n",
      "|   MSFT|     600.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in atexit._run_exitfuncs:                                                 \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juvid/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3791, in atexit_operations\n",
      "    self.history_manager.end_session()\n",
      "  File \"/home/juvid/.local/lib/python3.8/site-packages/IPython/core/history.py\", line 576, in end_session\n",
      "    self.db.execute(\"\"\"UPDATE sessions SET end=?, num_cmds=? WHERE\n",
      "sqlite3.OperationalError: disk I/O error\n"
     ]
    }
   ],
   "source": [
    "group_data.agg({'Sales': 'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c524a13-e97f-4908-8558-01f4064a187a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
