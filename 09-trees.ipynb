{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a01cedc-a277-46e1-8733-4f7c2bd4869b",
   "metadata": {},
   "source": [
    "# Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7461d9-6db3-4a40-9888-cbf261eaba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/16 10:59:06 WARN Utils: Your hostname, GBLON1WLZ13699 resolves to a loopback address: 127.0.1.1; using 10.164.15.145 instead (on interface eth2)\n",
      "21/09/16 10:59:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/juvid/miniconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/16 10:59:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('trees').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d655f0a-4957-4d7b-afbc-a180cf6ebe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c69c215-6d86-4c1c-a1db-e0c60db3d43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path('/home/juvid/Python-and-Spark-for-Big-Data-master/Spark_for_Machine_Learning/Tree_Methods/sample_libsvm_data.txt')\n",
    "data_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce76ef6-a672-400c-8747-f7797d5f2ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/16 10:59:11 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('libsvm').load(str(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bcb28a1-eb0e-4954-81ac-98d37cdd01a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6842787e-146d-4029-bfe4-243da5efda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d8d16aa-e006-4922-95c6-bdff2a2cc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier(numTrees=100)\n",
    "gbt = GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87e7a00-1c8a-48f9-8e7c-d3d667adbc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dtc_model = dtc.fit(train_df)\n",
    "rfc_model = rfc.fit(train_df)\n",
    "gbt_model = gbt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80b179c-eff1-4ad3-a569-01cfd8f31cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test_df)\n",
    "rfc_preds = rfc_model.transform(test_df)\n",
    "gbt_preds = gbt_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ff61f4-4623-48f6-aa47-d44757ecbeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|(692,[121,122,123...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[122,123,124...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  0.0|(692,[126,127,128...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  0.0|(692,[126,127,128...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[129,130,131...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[151,152,153...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[155,156,180...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[234,235,237...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[119,120,121...|   [29.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [0.0,39.0]|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_preds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c42a9-5be2-4c59-8cc1-86ebdc3288e0",
   "metadata": {},
   "source": [
    "# College dataset\n",
    "\n",
    "Use tree classification on a real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9d72e8d-043a-4ef3-9ea5-f56347854a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('/home/juvid/Python-and-Spark-for-Big-Data-master/Spark_for_Machine_Learning/Tree_Methods/College.csv')\n",
    "data_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb43f28-8952-4749-ac15-fa6645f0f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('tree').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab429496-ea78-4abe-a1b1-f4756f959856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(str(data_path), inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cf30124-a605-4012-b7d0-70e748909a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0d8b4-7230-431a-aa20-874c5aeba48c",
   "metadata": {},
   "source": [
    "We will try and predict whether or not the school is private."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d8cfb29-578b-46eb-b526-b7d12f183cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(School='Abilene Christian University', Private='Yes', Apps=1660, Accept=1232, Enroll=721, Top10perc=23, Top25perc=52, F_Undergrad=2885, P_Undergrad=537, Outstate=7440, Room_Board=3300, Books=450, Personal=2200, PhD=70, Terminal=78, S_F_Ratio=18.1, perc_alumni=12, Expend=7041, Grad_Rate=60)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d370318-02d3-432b-85a2-68a0e32190ee",
   "metadata": {},
   "source": [
    "We need to group all the features into vectors. For that, we'll use a `VectorAssembler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a591175-1dd7-443d-b50b-8016a991a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d49aa512-1412-41b0-9511-3e9485da72c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['School',\n",
       " 'Private',\n",
       " 'Apps',\n",
       " 'Accept',\n",
       " 'Enroll',\n",
       " 'Top10perc',\n",
       " 'Top25perc',\n",
       " 'F_Undergrad',\n",
       " 'P_Undergrad',\n",
       " 'Outstate',\n",
       " 'Room_Board',\n",
       " 'Books',\n",
       " 'Personal',\n",
       " 'PhD',\n",
       " 'Terminal',\n",
       " 'S_F_Ratio',\n",
       " 'perc_alumni',\n",
       " 'Expend',\n",
       " 'Grad_Rate']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae2a9069-8ff6-4136-bf32-38c587176f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\n",
    "'Apps',\n",
    "'Accept',\n",
    "'Enroll',\n",
    "'Top10perc',\n",
    "'Top25perc',\n",
    "'F_Undergrad',\n",
    "'P_Undergrad',\n",
    "'Outstate',\n",
    "'Room_Board',\n",
    "'Books',\n",
    "'Personal',\n",
    "'PhD',\n",
    "'Terminal',\n",
    "'S_F_Ratio',\n",
    "'perc_alumni',\n",
    "'Expend',\n",
    "'Grad_Rate'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a869ac0e-1878-473c-b673-04019ef2baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560d06d-5212-4880-afc2-0ea175136bff",
   "metadata": {},
   "source": [
    "The target output is a string, but we need to do some binary encoding to make mlspark work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b78063cd-f4f0-4227-a9ba-d07715d650fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01547974-52ad-4033-9364-1ac1781289bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='Private', outputCol='PrivateIndex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6c2e3-f397-4fb6-9e9c-0fcdf4d3e8d8",
   "metadata": {},
   "source": [
    "This one-liner is an alternative to a pipeline for transforming a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13e647b0-cc53-48cd-9404-1c5a66bd0a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_binarized = indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b218f4a0-84d8-4d78-9f1c-9d2511dbca6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_binarized.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1f0d5fa-0626-4e4f-af7d-546ab82163c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = output_binarized.select(['features', 'PrivateIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc4ba247-b693-4702-8e7d-b224fd73f81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|PrivateIndex|\n",
      "+--------------------+------------+\n",
      "|[1660.0,1232.0,72...|         0.0|\n",
      "|[2186.0,1924.0,51...|         0.0|\n",
      "|[1428.0,1097.0,33...|         0.0|\n",
      "|[417.0,349.0,137....|         0.0|\n",
      "|[193.0,146.0,55.0...|         0.0|\n",
      "|[587.0,479.0,158....|         0.0|\n",
      "|[353.0,340.0,103....|         0.0|\n",
      "|[1899.0,1720.0,48...|         0.0|\n",
      "|[1038.0,839.0,227...|         0.0|\n",
      "|[582.0,498.0,172....|         0.0|\n",
      "|[1732.0,1425.0,47...|         0.0|\n",
      "|[2652.0,1900.0,48...|         0.0|\n",
      "|[1179.0,780.0,290...|         0.0|\n",
      "|[1267.0,1080.0,38...|         0.0|\n",
      "|[494.0,313.0,157....|         0.0|\n",
      "|[1420.0,1093.0,22...|         0.0|\n",
      "|[4302.0,992.0,418...|         0.0|\n",
      "|[1216.0,908.0,423...|         0.0|\n",
      "|[1130.0,704.0,322...|         0.0|\n",
      "|[3540.0,2001.0,10...|         1.0|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9e19ce6-d785-4108-ad5a-7fa814c70b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_clean.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7541ec32-7b75-4c39-8163-88a831e99f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='PrivateIndex', featuresCol = 'features')\n",
    "rfc = RandomForestClassifier(labelCol='PrivateIndex', featuresCol = 'features', numTrees=150)\n",
    "gbt = GBTClassifier(labelCol='PrivateIndex', featuresCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83eac7a5-71ec-4d22-b131-ff41641f57e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dtc_model = dtc.fit(train)\n",
    "rfc_model = rfc.fit(train)\n",
    "gbt_model = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e8bcddf-958c-4cb5-8721-d088d4147124",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test)\n",
    "rfc_preds = rfc_model.transform(test)\n",
    "gbt_preds = gbt_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b4145ce-3ae7-4e62-a169-e911745395e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef75e484-8a63-45e2-99f1-95227963d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_eval = BinaryClassificationEvaluator(labelCol='PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6858f473-ae5d-4752-bfdf-adeba4356308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.9514933166248956\n"
     ]
    }
   ],
   "source": [
    "print('DTC')\n",
    "print(binary_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06a2ab7e-009b-49ba-87cd-fd1ae62bb779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC\n",
      "0.9675229741019217\n"
     ]
    }
   ],
   "source": [
    "print('RFC')\n",
    "print(binary_eval.evaluate(rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f16773e-051c-4618-a8cf-8ddbb56ef07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT\n",
      "0.9613617376775271\n"
     ]
    }
   ],
   "source": [
    "print('GBT')\n",
    "print(binary_eval.evaluate(gbt_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b20b5f1-9088-4b5c-92c5-20c089afd093",
   "metadata": {},
   "source": [
    "We can also grab other performance metrics from multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a263743c-81f7-47ef-a23f-2a1b28cf70d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e67a3d9-2183-4767-a728-8ab5207f14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(labelCol='PrivateIndex', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10db371e-531a-4e1c-999a-bb73c0d58eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9288888888888889"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_acc = acc_eval.evaluate(rfc_preds)\n",
    "rfc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ec7fb-7ea1-46f0-b298-62bc4b267fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
